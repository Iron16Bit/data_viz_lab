{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "title: \"Data visualization lab\"\n",
    "\n",
    "author: \"Shahryar Noei\"\n",
    "\n",
    "date: \"Mar 12, 2025\"\n",
    "\n",
    "topic: STILL DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(4561)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lord of the Rings!\n",
    "\n",
    "Here is a practical example on some untidy data created from [this data from the Lord of the Rings Trilogy](https://github.com/jennybc/lotr)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Film    Race  Female  Male\n",
      "0  The Fellowship Of The Ring     Elf    1229   971\n",
      "1  The Fellowship Of The Ring  Hobbit      14  3644\n",
      "2  The Fellowship Of The Ring     Man       0  1995\n",
      "3              The Two Towers     Elf     331   513\n",
      "4              The Two Towers  Hobbit       0  2463\n"
     ]
    }
   ],
   "source": [
    "lotr = pd.read_csv(\"./Data/lotr_untidy.csv\")\n",
    "print(lotr.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three rows per movie. For each movie, we have the total number of words spoken by characters of different races and genders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fship = lotr[lotr[\"Film\"].str.contains(\"Fellowship\")]\n",
    "ttow = lotr[lotr[\"Film\"].str.contains(\"Towers\")]\n",
    "rking = lotr[lotr[\"Film\"].str.contains(\"King\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Film</th>\n",
       "      <th>Race</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Return Of The King</td>\n",
       "      <td>Elf</td>\n",
       "      <td>183</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Return Of The King</td>\n",
       "      <td>Hobbit</td>\n",
       "      <td>2</td>\n",
       "      <td>2673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Return Of The King</td>\n",
       "      <td>Man</td>\n",
       "      <td>268</td>\n",
       "      <td>2459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Film    Race  Female  Male\n",
       "6  The Return Of The King     Elf     183   510\n",
       "7  The Return Of The King  Hobbit       2  2673\n",
       "8  The Return Of The King     Man     268  2459"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rking.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could imagine finding these three tables as separate worksheets in an Excel workbook. Or hanging out in some cells on the side of a worksheet that contains the underlying data raw data. Or as tables on a webpage or in a Word document.\n",
    "\n",
    "This format makes it easy for a *human* to look up the number of words spoken by female elves in The Two Towers. But this format actually makes it pretty hard for a *computer* to pull out such counts and, more importantly, to compute on them or graph them.\n",
    "\n",
    "### Exercises\n",
    "\n",
    "By working on the data as they are, answer these questions:\n",
    "\n",
    "1. What's the total number of words spoken by male hobbits?\n",
    "2. Which race has the highest total word count across all three movies, regardless of gender? (hint: `groupby` function)\n",
    "3. Does a certain race dominate a movie?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Total words spoken by male hobbits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8780\n"
     ]
    }
   ],
   "source": [
    "hobbits = lotr[lotr[\"Race\"].str.contains(\"Hobbit\")]\n",
    "male_hobbits = hobbits[\"Male\"]\n",
    "total = 0\n",
    "for val in male_hobbits:\n",
    "    total += val\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Race with highest word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hobbit\n"
     ]
    }
   ],
   "source": [
    "races = lotr.groupby(\"Race\")\n",
    "race_df = races.first()\n",
    "\n",
    "# Add a new column for total\n",
    "race_df[\"Total\"] = race_df[\"Male\"] + race_df[\"Female\"]\n",
    "\n",
    "race_most_characters = race_df[\"Total\"].idxmax()\n",
    "\n",
    "print(race_most_characters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dominant race per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fship:\t Hobbit\n",
      "ttow:\t Man\n",
      "rking:\t Man\n"
     ]
    }
   ],
   "source": [
    "races_fship = fship.groupby(\"Race\").first()\n",
    "races_ttow = ttow.groupby(\"Race\").first()\n",
    "races_rking = rking.groupby(\"Race\").first()\n",
    "\n",
    "races_fship[\"Total\"] = races_fship[\"Male\"] + races_fship[\"Female\"]\n",
    "races_ttow[\"Total\"] = races_ttow[\"Male\"] + races_ttow[\"Female\"]\n",
    "races_rking[\"Total\"] = races_rking[\"Male\"] + races_rking[\"Female\"]\n",
    "\n",
    "most_fship = races_fship[\"Total\"].idxmax()\n",
    "most_ttow = races_ttow[\"Total\"].idxmax()\n",
    "most_rking = races_rking[\"Total\"].idxmax()\n",
    "\n",
    "print(\"fship:\\t\", most_fship)\n",
    "print(\"ttow:\\t\", most_ttow)\n",
    "print(\"rking:\\t\", most_rking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does your approach scale if there were many more movies or if I provided you with updated data that includes all the `Races` (e.g. dwarves, orcs, etc.)?\n",
    "\n",
    "\n",
    "## From untidy to tidy\n",
    "\n",
    "### Import untidy Lord of the Rings data\n",
    "\n",
    "For the sake of this lesson, I loaded the (untidy) data from a single file and then split them into three data frames `fship`, `ttow`, and `rking`.\n",
    "\n",
    "I assume that data can be found as three plain text, delimited files, one for each film. How to liberate data from spreadsheets or tables in word processing documents is beyond the scope of this tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have one data frame per film, each with a common set of 4 variables. Step one in tidying this data is to glue them together into one data frame, stacking them up row wise. This is called row binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined LOTR Data:\n",
      "                         Film    Race  Female  Male\n",
      "0  The Fellowship Of The Ring     Elf    1229   971\n",
      "1  The Fellowship Of The Ring  Hobbit      14  3644\n",
      "2  The Fellowship Of The Ring     Man       0  1995\n",
      "3              The Two Towers     Elf     331   513\n",
      "4              The Two Towers  Hobbit       0  2463\n"
     ]
    }
   ],
   "source": [
    "lotr_combined = pd.concat([fship, ttow, rking], ignore_index=True)\n",
    "print(\"Combined LOTR Data:\")\n",
    "print(lotr_combined.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidy the untidy Lord of the Rings data\n",
    "\n",
    "We are still violating one of the fundamental principles of *tidy data*. \"Word count\" is a fundamental variable in our dataset and it's currently spread out over two variables, `Female` and `Male`. \n",
    "\n",
    "Conceptually, we need to gather up the word counts into a single variable and create a new variable `Gender` to track whether each count refers to females or males: we are moving from wide to long formats.\n",
    "\n",
    "### Exercise: Tidy the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Film    Race  Gender  Total\n",
      "0   The Fellowship Of The Ring     Elf  Female   1229\n",
      "1   The Fellowship Of The Ring  Hobbit  Female     14\n",
      "2   The Fellowship Of The Ring     Man  Female      0\n",
      "3               The Two Towers     Elf  Female    331\n",
      "4               The Two Towers  Hobbit  Female      0\n",
      "5               The Two Towers     Man  Female    401\n",
      "6       The Return Of The King     Elf  Female    183\n",
      "7       The Return Of The King  Hobbit  Female      2\n",
      "8       The Return Of The King     Man  Female    268\n",
      "9   The Fellowship Of The Ring     Elf    Male    971\n",
      "10  The Fellowship Of The Ring  Hobbit    Male   3644\n",
      "11  The Fellowship Of The Ring     Man    Male   1995\n",
      "12              The Two Towers     Elf    Male    513\n",
      "13              The Two Towers  Hobbit    Male   2463\n",
      "14              The Two Towers     Man    Male   3589\n",
      "15      The Return Of The King     Elf    Male    510\n",
      "16      The Return Of The King  Hobbit    Male   2673\n",
      "17      The Return Of The King     Man    Male   2459\n"
     ]
    }
   ],
   "source": [
    "lotr_tidy = pd.melt(lotr_combined, id_vars=[\"Film\", \"Race\"], var_name=\"Gender\", value_name=\"Total\")\n",
    "print(lotr_tidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy Lord of the Rings data\n",
    "\n",
    "Notice that tidy data is generally *taller and narrower*. It doesn't fit nicely on the page. Certain elements get repeated a lot, e.g. `Hobbit`. For these reasons, we often instinctively resist *tidy* data as inefficient or ugly. But, unless and until you're making the final product for a textual presentation of data, ignore your yearning to see the data in a compact form.\n",
    "\n",
    "## Benefits of tidy data\n",
    "\n",
    "With the data in tidy form, it's natural to *get a computer* to do further summarization or to make a figure. This assumes you're using language that is \"data-aware\", which R certainly is.\n",
    "\n",
    "Now revisit the last exercises and accomplish the same tasks using the tidy LOTR data.\n",
    "\n",
    "### What's the total number of words spoken by male hobbits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8780\n"
     ]
    }
   ],
   "source": [
    "hobbits = lotr_tidy[lotr_tidy[\"Race\"].str.contains(\"Hobbit\")]\n",
    "male_hobbits = hobbits[hobbits[\"Gender\"].str.contains(\"Male\")]\n",
    "total = 0\n",
    "for val in male_hobbits[\"Total\"]:\n",
    "    total += val\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which race has the highest total word count across all three movies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hobbit'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = lotr_tidy.groupby(\"Race\").agg(\"sum\")\n",
    "top_race = grouped[\"Total\"].idxmax()\n",
    "top_race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does a certain race dominate a movie? Does the dominant race differ across the movies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data manipulation\n",
    "\n",
    "## Data set: baby names\n",
    "\n",
    "Data file: `bnames.csv.bz2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and display the first and the last 15 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bnames.csv.bz2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bnames \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbnames.csv.bz2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(bnames\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m15\u001b[39m))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(bnames\u001b[38;5;241m.\u001b[39mtail(\u001b[38;5;241m15\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\gille\\Desktop\\DataVizLab\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gille\\Desktop\\DataVizLab\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\gille\\Desktop\\DataVizLab\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gille\\Desktop\\DataVizLab\\venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\gille\\Desktop\\DataVizLab\\venv\\lib\\site-packages\\pandas\\io\\common.py:783\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;66;03m# BZ Compression\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m compression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbz2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# Overload of \"BZ2File\" to handle pickle protocol 5\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# \"Union[str, BaseBuffer]\", \"str\", \"Dict[str, Any]\"\u001b[39;00m\n\u001b[1;32m--> 783\u001b[0m     handle \u001b[38;5;241m=\u001b[39m get_bz2_file()(  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m    784\u001b[0m         handle,\n\u001b[0;32m    785\u001b[0m         mode\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    786\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcompression_args,\n\u001b[0;32m    787\u001b[0m     )\n\u001b[0;32m    789\u001b[0m \u001b[38;5;66;03m# ZIP Compression\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m compression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;00m\n\u001b[0;32m    792\u001b[0m     \u001b[38;5;66;03m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;00m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;66;03m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\bz2.py:81\u001b[0m, in \u001b[0;36mBZ2File.__init__\u001b[1;34m(self, filename, mode, compresslevel)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid mode: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (mode,))\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filename, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)):\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp \u001b[38;5;241m=\u001b[39m \u001b[43m_builtin_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closefp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode_code\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bnames.csv.bz2'"
     ]
    }
   ],
   "source": [
    "bnames = pd.read_csv(\"bnames.csv.bz2\")\n",
    "print(bnames.head(15))\n",
    "print(bnames.tail(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your turn! Extract a name (possibly yours or a similar one). Plot the trend over time. What kind of geometry should you use for such a plot? Do you need to specify extra properties (e.g. aesthetics)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots look funny... what's going on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice with pandas functions\n",
    "\n",
    "1. In which year was your name (or a similar one) most popular? Least popular?\n",
    "2. Reorder the data frame containing the name of your choice from highest to lowest popularity\n",
    "3. On the data frame containing the name of your choice, add a new column that gives the number of babies per thousand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instr = pd.DataFrame({\n",
    "    \"name\": [\"John\", \"Paul\", \"George\", \"Ringo\", \"Stuart\", \"Pete\"],\n",
    "    \"instrument\": [\"guitar\", \"bass\", \"guitar\", \"drums\", \"bass\", \"drums\"]\n",
    "})\n",
    "people = pd.DataFrame({\n",
    "    \"name\": [\"John\", \"Paul\", \"George\", \"Ringo\", \"Brian\"],\n",
    "    \"band\": [True, True, True, True, False]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try all the different joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_join = instr.merge(people, how=\"left\")\n",
    "right_join = instr.merge(people, how=\"right\")\n",
    "inner_join = instr.merge(people, how=\"inner\")\n",
    "full_join = instr.merge(people, how=\"outer\")\n",
    "\n",
    "print(left_join)\n",
    "print(right_join)\n",
    "print(inner_join)\n",
    "print(full_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people[\"instrument\"] = [\"vocals\", \"vocals\", \"backup\", \"backup\", \"manager\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you combine `instr` and `people` now that `people` has this additional column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_join_wrong = instr.merge(people, how=\"outer\")\n",
    "print(full_join_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_join_updated = instr.merge(people, on=\"name\", how=\"outer\")\n",
    "print(full_join_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Read the \"births.csv\" file attached to this lab.\n",
    "\n",
    "Convert from proportions of baby names to absolute numbers by combining `bnames` with this new data set, and then performing the proper calculation.\n",
    "\n",
    "Compute how many people with each name were born over all years.\n",
    "\n",
    "Repeat the above, this time using `soundex` instead of `name`, thus answering the question: what is the most common sound? Then find out what name it corresponds to (hint: use another join)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
